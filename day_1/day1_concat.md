
# Balancing Evidence and Intuition: Aligning HR Analytics to Business Objective

## Erdmann and van Leeuwen - HR Analytics - Shell

_I went with the hope of understanding how we might be able to quantify DoD performance_

## Key Takeaways

  - Found that team leadership ws an important driver of sales performance. Used these results to suggest team leadership programs. 
  - It's clear this team has spent a lot of time thinking about appropriate project structure
  - Multi-level modeling is a good approach, these ideas are important for modeling sales performance
      + Controlling for heterogeneity _across_ teams
  - Emphasized importance of cross-functional teams and heightened collaboration

## Talk Outline

  - How analytics is used for sales and marketing
  - Shell has 80,000 employees
  - Skilled people X high motivation X opportunity to contribute
      + recruitment / professional development
      + what contributes to motivation?
          * which managers are better/worse motivators? why?

Transition from beliefs to evidence

  - Many HR practices are based on experience, intuition, and beliefs
  - Evidence and analytics does not replace, but __supplements intuition__, __experience__, and beliefs

The job of analytics is not to "do magic", but (along with business users) understand where problems are, __what problems may be solveable__, and what the impact of solving this problem will be

Turning questions into actions

  - Which questions? What data? Which rules? What insights? Which actions?
  - Shell has a generic project approach 

Project Spark

  - Combined HR data and sales data
      + about 1,500 sales managers
  - How to optimize return on human capital?
  - About an 8 month project
  - Research - Conceptual Model - Data Identification - Data ACquisition - Survey Design - Survey - Recommendations - Report - Action
  - They use hierarchical modeling
      + This is a very reductive summary...
  - They found (using results from employee surveys) that team leadership was a strong predictor of sales performance
      + This finding led to the actionable result of increased investment in leadership development programs
  - Personality traits are strong drivers of sales performance

Key takeaways from Shell's Project Spark

  - Collaboration
      + collaborate closely with the business to generate _business value_
          * cross-functional teams
  - Commitment
      + After leadership approval, it is important for leaders to commit to their own involvement and willingness to allocate resources
  - Change
      + Integrate change management in early stage



# Delivering the Business Value of Analytics 

## CEO Decision Managment Solutions - James Taylor

## Key Takeaways

  - Looked at what barriers exist in deploying an analytic solution (how to make analytics actionable __and__ acted on)
      + Why do these barriers exist? What are these barriers?
      + How do we combat these barriers? Workaround these barriers?
  - Analytic teams are done when the business changes its decision-making in a way that creates business value __and not before__
  - What is involved in implementing an "analytic"?
      + Case for more time being spent on building decision/business understanding
      + Use a decision model to mix and match technologies _within_ the larger set of analytic technologies 
  - Issues with the "data-first" fallacy
      + "data first" - data scientists drive decisions in modeling / analytics project
      + Results in interesting model, but not models that will add business value
      + Make sure the analytic will be actionable __before you build it__
  - How?
      + Decisions first
      + Let the experts speak
          * Ask the question "how do you do your day job now?" and follow up with many "why" questions
              - __Do not start__ with "what do you want analytics to do"
          * making changes to existing business practices is hard, need to understand what can / should be augmented by an analytic
      + Adopt business rules
      + Analytics don't stand alone 
          * projects should start with a diverse group of individuals from different units in the business in a room to discuss
      + Change the business
          * Incremental improvement to some standard decision-making process


## Rough Outline of Talk

(slides available as pdf)

Delivering business value - how?
    make products __cheaper__, __better__, __sooner__, __more satisfying__

Why don't some analytics projects not add business value?
    not actionable: solves wrong problem, too hard to use, too expensive
    not actioned: not integrated, not believed, not used

Barriers to "actionizing" analytics are widespread

Key problem: can't implement in workflow of front-line workforce

Valuable analytic - ....

How to use actionable analytics in front line (building valuable analytics)

  - build it
      + addresses a problem or opportunity
          * can be used, is believed, embedded in systems
          * if analytics does not lead to more informed decisions and more effective actions, then why do it at all?

Critical success factors

  1. adopt a business-decision-centric approach
  2. change how you deine business understanding
  3. consider decision makin technologies as a set of technologies, not standalone

Business-centric approach (CRoss Industry Standard Process for Data Mining CRISPDM)

  - Put __business understanding and business problem__ first
      + what is business value? __need to have this defined__
  - Evaluate the model (not in statistical terms, but in terms of __business impact__) 
  - Deploy
  - Repeat 

Put decisions first for business understanding (__requires input from the business__)
  
  - What business measures?
  - What decisions have an impact?
      + What can / do we want to change?
  - Which decision should we improve?
  - What does improve mean?

Make the project about the decision, not the analytics

Analyzing a decision - __decision understanding__
  
  1. Decision (specific questions and allowed answers)
  2. Data
  3. Sub-decisions
  4. Knowledge

Business (people) Understanding

  - Let experts speak
      + Naive data scientist: "why do I need to talk to the people, when I have the data?"
          * Front-line people are the ones implementing the analytic, analytic needs to match (match? augment? improve?) their decision-making processes (i.e. how they work)
  - Model the decision
  - Let experts frame the problem
      + What do they want?

Mix and match decision-making technology

  - Most decisions need more than just predictions
      + Big scope and large set of technologies (descriptive analysis, maching learning, predictive analytics)

Digital Decisioning

  - Culture of digital decisions-first design thinking
  - Nexus of business rules, data, analytics, and machine learning models
  - __One__ smarter, automated decision can be worth millions in terms of customer acquisition retention and/or operational efficiency

Analytic teams are done when the business changes its decision-making in a way that creates business value __and not before__



# Helping Business Be Predictable

## Theresa Kushner - SVP BI - Dell

## Key takeaways

  - Dell's predictive analytics / artificial intelligence / machine learning impacts every facet of their business
  - They ask a lot of "how can we improve X" or "how do we prioritize Y better" questions across each facet of their business
  - Facts and Alternatives 
  - People doing projects in one area are aware of projects being done in other areas
  - A key to success is collaboration
  - Similar to AirBnB (and related to our ongoing improving data literacy discussions), Dell has also prioritized organization-wide data literacy
      + Made comparison to computer literacy in 1980s and 1990s.

## Outline of Talk

How Artificial Intelligence and Machine Learning are being used at Dell

Mission statement for AI:

"Provide value to the business by delivering profitable impact through artificial intelligence and machine learning.

Maintain analytical rigor through innovation, collaboration, cross-functional learning..."

How Dell uses predictive analytics - an enterprise example

Predictive analytics is a part of every business function at enterprises. It helps enhance customer experience by improving the behind the scenes operations. The results of predictive analytics are followed throughout the customer lifecycle.

  - product development
      + how do customers feel about products
      + what price
      + competition
      + demand
  - marketing
      + optimize website for customer experience
      + recommend products
      + when, where, and what campaigns should I launch
      + how to optimize marketing investments
  - Sales - first place to go for implementing an analytical solution: easy to measure and quantify success ($$$)
      + how to sell right solutions to customers
      + how to improve sales operations
      + how to identify peripherals or other products for commerical customers
          * recommendation engines
              - how could we use recommendation engines at WFAA?
  - Finance / order fulfillment
      + help customers acquire attractive credit terms?
      + have enough inventory?
      + meeting order delivery commitments
      + best estimate delivery time
  - Services
      + what best value service to offer and to whom
      + price offers better
      + improve customer experience
      + total cost to serve

Keys to Success

  - Collaboration
      + Improve collaboration between "older" generations and "younger" generations
          * Demystifying data science and analytics
          * Change management

Make your organizations data literate

  - Teach __all__ organization employees, especially exces, the triple-A approach to be data literate
      + Awareness: being aware of what is out there with data
      + Ability: what can / needs to be done with it
      + Art: telling the data story
  - Data literacy evangelists




## LSTM Neural Networks for Time Series Analysis

## James McCaffrey - Microsoft Research

## Key Takeaways

Not much right now

## Talk Outline

  - What is a time series problem?
  - Common standard approaches
      + AR, SimpleExponentialSmoothing, MA
  - Not-So-Common Approaches
      + Deep neural networks
      + LSTM network
  - Different techniques work differently well for different problems
      + length of time series, seasonality, stationarity, ...
      + there is not _only one way_
  - LSTM neural networks
      + have states
          * allows for contextual understanding (natural language processing)
          * sequencing
      + recurrence: output depends on current input (t) and previous output (t-1)
      + image for LSTM
  - Sequence length is an important hyperparameter to tune
  - Length of memory also important hyperparameter
  - Tuning is (probably) different for anomaly detection vs. forecasting


# Obstacles to Operationalizing Analytics and Strategies to Overcome Them

## Dave Pahl - Senior Director, Head of Analytics and Decision Sciences - Northwestern Mutual

## Key Takeaways from Session

  - Interesting perspectives on project management and steps needed to implement an analytical model
  - Get buy-in, more software-development type project management for analytics, take small steps, prove it, go with the flow while going against it, persevere
  - Important to take small steps in deploying an analytical model, thinking very carefully about what is being implemented, how it will be measured, whom it will impact
      + How should projects be prioritized?
          * Upper-level decision makers across the business should be involved in the prioritizing of analytics projects
      + Chunking a problem with a lot of business input

## Rough Outline of Talk

  - Get buy-in of analytic technologies
      + took 3.5 years to implement _first_ predictive model at Northwestern Mutual
      + Struggled to find the _right_ business users to push the analytical models through the enterprise
      + Need to get agreement throughout the enterprise
          * Prioritizing projects that can leverage analytics
  - Run the development
      + What didn't work: two person team of data engineers and data scientist
      + What did work: more diverse group of people working on different facets of a problem (data engineers, data scientists, project managers, engagement professionals, business subject experts)
          * Hard stop if business couldn't devote at least one subject expert on project
  - Take small steps
      + __don't try to do it all at once__
      + Break the problem into little pieces
      + Not everything needs to be solved right away!
  - Prove it
      + Experimentation and measurement helps get business leaders to accept it, want it, and change for it
      + Think carefully about design of experiments
  - Go with the flow, while going against it
      + Analytics and data science has reputation of "black magic"
          * Demystify these techniques by showing how small parts of the business can be changed with understandable methodologies
  - Persevere
      + It's going to take a while!


# Simplicity is Genius: Bridging the Gap between Data Scientists and Senior Leadership

## James Carson - Team Leader, Quicken Loans

_He went kind of quikly through these slides. I hope these are made available._

## Key Takeaways

  - A lot of this talk was about communication of results and how to get buy-in from senior leaderships and allowing data science teams to do what they do best
      + This was the second talk that emphasized how models should be explained without confusing / scaring a business user
          * I think we're getting a lot better at this!
  - How do we get business users comfortable with allowing machines/algorithms/data science to make decisions?
      + Show impact in terms business owners can understand
  - Also discussed analytics / data science divide
      + First time I've heard a productive discussion of why this divide matters
          * Divide is important when thinking about where each group should be positioned within an organization
      + Analytics: inform the actor, Data Science: be the actor
  - Humans should still be involved in the vision of an organization
      + Senior leadership should not be solutioning
  - A vision for data science should be a vision for your business itself
      + don't need a vision for ML/AI

## Rough Outline of Talk

Data scientists don't know how to talk to senior leadership

Data science takes decision making away from senior leadership

Analytics - telling the story
    output: insights
    goal: inform the actor
    focus: the "what"
    what can we learn about X?
    positioned: in trenches with senior leadership, advising strategy and tactics

Data Science
    output: decisions
    goal: be the actor
    focus: the "how"
    how can we learn to do X?
    positioned: still solicit feedback from senior leadership, but exists with a bit more distance from them

Explaining your model: give high-level summaries relevant to business users

Focus on evaluation criteria:

  - what does accuracy mean? 
  - what's the value of getting it right?
      + what's the risk if we got it wrong?

Why did you solve the problem this way?
    - Problem often dictates the solution

No fancy jargon
    - clearly state: expected value, effort and deadline, assumptions you're making, hypothesis you're testing 




# Steps to Overcome the Greatest Challenges to Analytics Deployment

## Marco Vriens - Kwantum Analytics

_Got to this session a bit late, previous session went long._

## Key Takeaways

  - What makes an analytical project successful?
      + A lot of work needs to be done _after_ the model has been built
  - How to approach a project acting as a consultant
      + What is the decision we are trying to change / improve?
  - Another talk highlighting collaboration, starting a project with the decision in mind, and demonstrating the distinct business value of a project

## Talk Outline

Selecting an analytical target

  - market dynamics
      + where is the market going?
  - market share dynamics
      + if market is stagnant, how to increase share?
          * how can I win market share - what levers should I pull?
              - discrete choice modeling
          * which customers are most likely loyal at risk or switchable?
  - marketing dynamics
      + marketing mix modeling
      + which marketing activities are working and which are not?
          * experimentation can be used after statistical results are presented
  - customer dynamics

Best way to use / implement analytics: start with a decision in mind

  - Can do analysis and insights, but without looking at a decision, hard to deploy

What do successful analytical projects have in common?

> Trust, partnership with senior leadership, advanced analytics, multiple steps, validation (experimentation, simulation, results can be trusted)

  - Advanced analytics
  - From modeling results to so-what (simulation & experimentation)
  - Performed over multiple steps
  - Integration across multiple datasets
  - Validation: results can be trusted
  - Partnership with stakeholders
  - CEO driven
  - Deepenining of insights
  - Decision support system: recommendation engine
  - Importance of process that was being augmented / improved
  - Transportability

Questions to ask after analytical project has been "completed"

  - Do decision makers know about the insights?
  - Do they understand the insights?
  - Are the insights: credible, actionable, accepted?
  - Are the insights acted on and acted on correctly?

Management of Analytics 

  - Training
      + of analytics team __and__ stakeholders
  - Decision support systems
  - Analytics portal and insights search engine
      + Make the results of analytical efforts accessible to the organization








# Brief Summaries of Vendor Presentations

## Data Robot

Automated data science / machine learning tool.

## Pitney Bowes

Graph databases and what you can do with them.

Kind of relates to the BUS network analysis.

I _still_ don't know a graph database use case for WFAA

## tellius

Data exploration / reporting tool. Cool search feature. 

